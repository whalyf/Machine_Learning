# -*- coding: utf-8 -*-
"""Modulo3_Previsao_do_uso_de_bicicletas_alugadas_whalyf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12FqheLwEqHPnwd23yFSSoCf2RfB_xhLC

# Definição do problema

- Referência da base de dados: 
    - This Hadi Fanaee-T
    - Laboratory of Artificial Intelligence and Decision Support (LIAAD), University of Porto INESC Porto, Campus da FEUP Rua Dr. Roberto Frias, 378 4200 - 465 Porto, Portugal

# Etapa 1: Importação das bibliotecas
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
tf.__version__

"""# Etapa 2: Importação da base de dados"""

bike = pd.read_csv('bike-sharin-daily.csv')

bike

bike.head(5)

bike.tail(10)

bike.info()

bike.describe()

"""# Etapa 3: Limpeza da base de dados"""

sns.heatmap(bike.isnull());

bike = bike.drop(labels=['instant'], axis = 1)

bike.head()

bike = bike.drop(labels = ['casual', 'registered'], axis = 1)

bike

bike.dteday = pd.to_datetime(bike.dteday, format = '%m/%d/%Y')

bike.head()

bike.index = pd.DatetimeIndex(bike.dteday)

bike.head()

bike = bike.drop(labels = ['dteday'], axis=1)

bike.head()

"""# Etapa 4: Visualização da base de dados"""

bike['cnt'].asfreq('W').plot(lineWidth = 3);
plt.title('Bike usage per week')
plt.xlabel('Week')
plt.ylabel('Bike rental');

bike['cnt'].asfreq('M').plot(lineWidth = 3);
plt.title('Bike usage per month')
plt.xlabel('Week')
plt.ylabel('Bike rental');

bike['cnt'].asfreq('Q').plot(lineWidth = 3);
plt.title('Bike usage per quarter')
plt.xlabel('Week')
plt.ylabel('Bike rental');

sns.pairplot(bike)

X_numerical = bike[['temp', 'hum', 'windspeed', 'cnt']]

X_numerical

sns.pairplot(X_numerical);

sns.heatmap(X_numerical.corr(), annot = True);

"""# Etapa 5: Tratamento das bases de dados"""

X_cat = bike[['season', 'yr', 'mnth', 'holiday', 'weekday','workingday','weathersit']]

X_cat.head()

"""Domingo 0
Segunda 1

Domingo - 0 1 0
Segunda - 1 0 0
Terça   - 0 0 1
"""

from sklearn.preprocessing import OneHotEncoder
onehotencoder = OneHotEncoder()
X_cat = onehotencoder.fit_transform(X_cat).toarray()

X_cat.shape

X_cat = pd.DataFrame(X_cat)

X_cat.head()

X_numerical.head()

X_numerical = X_numerical.reset_index()

X_numerical.head()

X_all = pd.concat([X_cat, X_numerical], axis = 1)

X_all.head()

X_all = X_all.drop(labels= ['dteday'], axis = 1)

X_all.head()

x = X_all.iloc[:, :-1].values

y = X_all.iloc[:, -1:].values

x.shape

y.shape

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
y = scaler.fit_transform(y)

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)

X_train.shape

X_test.shape

"""# Etapa 6: Construção e treinamento do modelo"""

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(units = 100, activation = 'relu',input_shape=(35,)))
model.add(tf.keras.layers.Dense(units = 100, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 100, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))

model.summary()

model.compile(optimizer='Adam',loss='mean_squared_error')

epochs_hist = model.fit(X_train, y_train, epochs = 25, batch_size = 50, validation_split=0.2)

"""# Etapa 7: Avaliação do modelo"""

epochs_hist.history.keys()

plt.plot(epochs_hist.history['loss'])
plt.plot(epochs_hist.history['val_loss'])
plt.title('Model loss progress during training')
plt.xlabel('Epochs')
plt.ylabel('Training and validation loss')
plt.legend(['Training Loss', 'Validation Loss']);

y_predict = model.predict(X_test)

y_predict

plt.plot(y_test, y_predict, "^" ,color = 'r')
plt.xlabel('Model predicitons')
plt.ylabel('True Values')

y_predict_orig = scaler.inverse_transform(y_predict)
y_test_orig = scaler.inverse_transform(y_test)

plt.plot(y_test_orig, y_predict_orig, "^" ,color = 'r')
plt.xlabel('Model predicitons')
plt.ylabel('True Values')

k = X_test.shape[1]
k

n = len(X_test)
n

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt

mae = mean_absolute_error(y_test_orig, y_predict_orig)
mse = mean_squared_error(y_test_orig, y_predict_orig)
rmse = sqrt(mse)
r2 = r2_score(y_test_orig, y_predict_orig)
adj_r2 = 1-(1-r2) * (n-1) / (n-k-1)

print('MAE:',mae, '\nMSE:', mse, '\nRMSE:', rmse, '\nR2:', r2, '\nADJ R2:', adj_r2)