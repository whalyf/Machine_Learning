# -*- coding: utf-8 -*-
"""Modulo5_Classificacao_de_Texto_e_Analise_de_Sentimentos_whalyf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P9bHrzXZbwhXhd0xwv-hnfPVxqbM4TXN

# Projeto 5: Classificação de Texto e Análise de Sentimentos

- Base de dados: www.kaggle.com/sid321axn/amazon-alexa-reviews

# Etapa 1: Importação das bibliotecas
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
tf.__version__

"""# Etapa 2: Importação da base de dados"""

df_alexa = pd.read_csv('/content/amazon-alexa.tsv', sep = '\t')

df_alexa.head()

df_alexa.keys()

df_alexa.tail()

df_alexa['verified_reviews']

"""# Etapa 3: Visualização dos dados"""

positive = df_alexa[df_alexa['feedback'] == 1]

positive

negative = df_alexa[df_alexa['feedback'] == 0]

negative

sns.countplot(df_alexa['feedback'], label = 'Count');

sns.countplot(x = 'rating', data = df_alexa);

df_alexa['rating'].hist(bins = 5);

plt.figure(figsize =(40,15))
sns.barplot(x = 'variation', y = 'rating', data = df_alexa, palette = 'deep');

"""# Etapa 4: Limpeza dos dados"""

df_alexa = df_alexa.drop(['date','rating'], axis = 1)

df_alexa.head()

variation_dummies = pd.get_dummies(df_alexa['variation'])
variation_dummies

df_alexa.drop(['variation'], axis = 1, inplace = True)

df_alexa.head()

df_alexa = pd.concat([df_alexa, variation_dummies], axis = 1)

df_alexa.head()

"""# Exemplo de tokenização"""

from sklearn.feature_extraction.text import CountVectorizer

sample_data = ['This is the first document.',
               'This document is the second document.',
               'And this is the third one.',
               'Is this the first document?']

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(sample_data)

print(vectorizer.get_feature_names())

print(X.toarray())

"""# Tokenização da base de dados"""

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
alexa_countvectorizer = vectorizer.fit_transform(df_alexa['verified_reviews'])

alexa_countvectorizer.shape

type(alexa_countvectorizer)

print(vectorizer.get_feature_names())

print(alexa_countvectorizer.toarray())

df_alexa.drop(['verified_reviews'],axis = 1, inplace = True)

df_alexa.head()

reviews = pd.DataFrame(alexa_countvectorizer.toarray())

reviews.head()

df_alexa = pd.concat([df_alexa, reviews], axis = 1)

df_alexa.head()

X = df_alexa.drop(['feedback'], axis = 1)

X

"""y = df_alexa['feedback']"""

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)

X_train.shape

X_test.shape

"""# Etapa 5: Construção e treinamento do modelo"""

# 4060 -> 400 -> 400 -> 1
classifier = tf.keras.models.Sequential()
classifier.add(tf.keras.layers.Dense(units = 400, activation = 'relu', input_shape = (4060,)))
classifier.add(tf.keras.layers.Dense(units = 400, activation = 'relu'))
classifier.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

classifier.summary()

classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

epochs_hist = classifier.fit(X_train, y_train, epochs = 10)

"""# Etapa 6: Avaliação do modelo"""

from sklearn.metrics import classification_report, confusion_matrix

y_pred_train = classifier.predict(X_train)
y_pred_train

y_pred_train = (y_pred_train > 0.5)
y_pred_train

cm = confusion_matrix(y_train, y_pred_train)
cm

sns.heatmap(cm, annot = True);

y_pred_test = classifier.predict(X_test)
y_pred_test = (y_pred_test > 0.5)
cm = confusion_matrix(y_test, y_pred_test)
cm

sns.heatmap(cm, annot = True);

epochs_hist.history.keys()

plt.plot(epochs_hist.history['loss'])
plt.title('Model loss progress during training')
plt.xlabel('Epoch')
plt.ylabel('Training loss')
plt.legend(['Training loss'])

plt.plot(epochs_hist.history['accuracy'])
plt.title('Model accuracy progress during training')
plt.xlabel('Epoch')
plt.ylabel('Training accuracy')
plt.legend(['Training accuracy']);